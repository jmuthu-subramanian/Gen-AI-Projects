{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 📚 Character-Level Text Generator with LSTM (Colab Version)\n",
        "# Author: ChatGPT\n",
        "\n",
        "# Step 1: Install dependencies (if needed)\n",
        "!pip install tensorflow --quiet\n",
        "\n",
        "# Step 2: Load Dataset\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import requests"
      ],
      "metadata": {
        "id": "jKQY14uvUyTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "l8La-c6cUClT",
        "outputId": "7be9fc0a-1f38-4250-c959-e8c2c67ba38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length: 148080 characters\n",
            "Number of sequences: 147980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10ms/step - accuracy: 0.3221 - loss: 2.5393\n",
            "Epoch 2/3\n",
            "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 11ms/step - accuracy: 0.4921 - loss: 1.7740\n",
            "Epoch 3/3\n",
            "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11ms/step - accuracy: 0.5432 - loss: 1.5489\n",
            "\n",
            "--- Generated Text ---\n",
            "\n",
            "Alice was beginning to get very tired themee some the was that would get the exepper there sorn into the said to be a little she\n",
            "herself, and the said, and were was it she had the Hatter. There was the jury arain the Queen.\n",
            "\n",
            "“I should thing you the erecully begin it, a lary grow the\n",
            "seemed to here for hand that the exear.”\n",
            "\n",
            "The Mouse of them was she could harder creatious, and she was not the looks the ratter, and there was a li\n"
          ]
        }
      ],
      "source": [
        "# Download a sample dataset (Alice in Wonderland)\n",
        "url = \"https://www.gutenberg.org/files/11/11-0.txt\"\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "\n",
        "print(f\"Corpus length: {len(text)} characters\")\n",
        "\n",
        "# Step 3: Character Mapping\n",
        "chars = sorted(set(text))\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx_to_char = {i: ch for ch, i in char_to_idx.items()}\n",
        "\n",
        "# Step 4: Create Sequences\n",
        "SEQ_LENGTH = 100\n",
        "STEP = 1\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - SEQ_LENGTH, STEP):\n",
        "    sequences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_chars.append(text[i + SEQ_LENGTH])\n",
        "\n",
        "print(f\"Number of sequences: {len(sequences)}\")\n",
        "\n",
        "# Step 5: Vectorize the sequences\n",
        "X = np.zeros((len(sequences), SEQ_LENGTH), dtype=np.int32)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool_)\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    X[i] = [char_to_idx[c] for c in seq]\n",
        "    y[i, char_to_idx[next_chars[i]]] = 1\n",
        "\n",
        "# Step 6: Build the LSTM Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(chars), output_dim=64, input_length=SEQ_LENGTH),\n",
        "    LSTM(256),\n",
        "    Dense(len(chars), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Step 7: Train the Model (short training for demo purposes)\n",
        "model.fit(X, y, batch_size=64, epochs=3)\n",
        "\n",
        "# Step 8: Generate Text\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds + 1e-8) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    return np.random.choice(len(preds), p=preds)\n",
        "\n",
        "def generate_text(seed_text, length=400, temperature=1.0):\n",
        "    generated = seed_text\n",
        "    input_seq = [char_to_idx.get(c, 0) for c in seed_text]\n",
        "\n",
        "    for _ in range(length):\n",
        "        pad_seq = tf.keras.preprocessing.sequence.pad_sequences([input_seq], maxlen=SEQ_LENGTH)\n",
        "        preds = model.predict(pad_seq, verbose=0)[0]\n",
        "        next_idx = sample(preds, temperature)\n",
        "        next_char = idx_to_char[next_idx]\n",
        "        generated += next_char\n",
        "        input_seq.append(next_idx)\n",
        "        input_seq = input_seq[-SEQ_LENGTH:]\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Step 9: Try it!\n",
        "seed = \"Alice was beginning to get very tired \"\n",
        "generated_text = generate_text(seed, temperature=0.5)\n",
        "print(\"\\n--- Generated Text ---\\n\")\n",
        "print(generated_text)\n"
      ]
    }
  ]
}